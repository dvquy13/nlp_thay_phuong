{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "from time import time\n",
    "from trie import Trie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw = []\n",
    "for f in os.listdir(os.path.join(os.getcwd(), \"data/brown\")):\n",
    "    with open(\"./%s/%s\" % ('data/brown', f)) as openned:\n",
    "        raw += openned.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_sent(raw_txt):\n",
    "    return list(filter(lambda x: x != '\\n', raw_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The/at-hl primary/jj-hl decomposition/nn-hl theorem/nn-hl \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_sent(raw)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Preprocessor():\n",
    "    def __init__(self):\n",
    "        self.punc_regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    \n",
    "    @staticmethod\n",
    "    def split_word(s):\n",
    "        splitted = [x.strip().replace(\"\\n\", \"\").replace(\"\\t\", \"\").lower() for x in s.split()]\n",
    "        return splitted\n",
    "    \n",
    "    @staticmethod\n",
    "    def rm_tag(s):\n",
    "        return re.sub(r\"(\\w+)(/.+$)\", r\"\\1\", s)\n",
    "    \n",
    "    def rm_punc(self, s):\n",
    "        return self.punc_regex.sub(\"\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert Preprocessor.split_word(\"\\tThe/at jury/nn  presentments/nns Georgia's/np$ \") == [\n",
    "    \"the/at\",\n",
    "    \"jury/nn\",\n",
    "    \"presentments/nns\",\n",
    "    \"georgia's/np$\"\n",
    "]\n",
    "\n",
    "assert Preprocessor.rm_tag(\"The/at\") == (\"The\")\n",
    "assert Preprocessor.rm_tag(\"county/nn-t1\") == (\"county\")\n",
    "assert Preprocessor.rm_tag(\"georgia's/np$\") == (\"georgia's\")\n",
    "\n",
    "assert Preprocessor().rm_punc(\"georgia's\") == (\"georgias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor()\n",
    "\n",
    "def preprocessing(sent):\n",
    "    split_ed = Preprocessor.split_word(sent)\n",
    "    rm_tag_ed = [Preprocessor.rm_tag(w) for w in split_ed]\n",
    "    rm_punc_ed = [preprocessor.rm_punc(w) for w in rm_tag_ed]\n",
    "    return filter(lambda x: x != \"\", rm_punc_ed)\n",
    "    \n",
    "assert preprocessing(\"\\tThe/at said/vbd ,/, ``/`` deserves/vbz Georgia's/np$ laws/nns ``/`` ''/'' ./.\\n\") == [\n",
    "    \"the\",\n",
    "    \"said\",\n",
    "    \"deserves\",\n",
    "    \"georgias\",\n",
    "    \"laws\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing took 7.976245\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing\n",
    "t0 = time()\n",
    "clean = filter(lambda x: x != [], [preprocessing(s) for s in raw])\n",
    "print(\"Preprocessing took {:3f}\".format(time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['64', 'hl'],\n",
       " ['the', 'primary', 'decomposition', 'theorem'],\n",
       " ['we',\n",
       "  'are',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'study',\n",
       "  'a',\n",
       "  'linear',\n",
       "  'operator',\n",
       "  't',\n",
       "  'on',\n",
       "  'the',\n",
       "  'finitedimensional',\n",
       "  'space',\n",
       "  'v',\n",
       "  'by',\n",
       "  'decomposing',\n",
       "  't',\n",
       "  'into',\n",
       "  'a',\n",
       "  'direct',\n",
       "  'sum',\n",
       "  'of',\n",
       "  'operators',\n",
       "  'which',\n",
       "  'are',\n",
       "  'in',\n",
       "  'some',\n",
       "  'sense',\n",
       "  'elementary'],\n",
       " ['we',\n",
       "  'can',\n",
       "  'do',\n",
       "  'this',\n",
       "  'through',\n",
       "  'the',\n",
       "  'characteristic',\n",
       "  'values',\n",
       "  'and',\n",
       "  'vectors',\n",
       "  'of',\n",
       "  't',\n",
       "  'in',\n",
       "  'certain',\n",
       "  'special',\n",
       "  'cases',\n",
       "  'ierb',\n",
       "  'when',\n",
       "  'the',\n",
       "  'minimal',\n",
       "  'polynomial',\n",
       "  'for',\n",
       "  't',\n",
       "  'factors',\n",
       "  'over',\n",
       "  'the',\n",
       "  'scalar',\n",
       "  'field',\n",
       "  'f',\n",
       "  'into',\n",
       "  'a',\n",
       "  'product',\n",
       "  'of',\n",
       "  'distinct',\n",
       "  'monic',\n",
       "  'polynomials',\n",
       "  'of',\n",
       "  'degree',\n",
       "  '1'],\n",
       " ['what', 'can', 'we', 'do', 'with', 'the', 'general', 't'],\n",
       " ['if',\n",
       "  'we',\n",
       "  'try',\n",
       "  'to',\n",
       "  'study',\n",
       "  't',\n",
       "  'using',\n",
       "  'characteristic',\n",
       "  'values',\n",
       "  'we',\n",
       "  'are',\n",
       "  'confronted',\n",
       "  'with',\n",
       "  'two',\n",
       "  'problems'],\n",
       " ['first',\n",
       "  't',\n",
       "  'may',\n",
       "  'not',\n",
       "  'have',\n",
       "  'a',\n",
       "  'single',\n",
       "  'characteristic',\n",
       "  'value'],\n",
       " ['this',\n",
       "  'is',\n",
       "  'really',\n",
       "  'a',\n",
       "  'deficiency',\n",
       "  'in',\n",
       "  'the',\n",
       "  'scalar',\n",
       "  'field',\n",
       "  'namely',\n",
       "  'that',\n",
       "  'it',\n",
       "  'is',\n",
       "  'not',\n",
       "  'algebraically',\n",
       "  'closed'],\n",
       " ['second',\n",
       "  'even',\n",
       "  'if',\n",
       "  'the',\n",
       "  'characteristic',\n",
       "  'polynomial',\n",
       "  'factors',\n",
       "  'completely',\n",
       "  'over',\n",
       "  'f',\n",
       "  'into',\n",
       "  'a',\n",
       "  'product',\n",
       "  'of',\n",
       "  'polynomials',\n",
       "  'of',\n",
       "  'degree',\n",
       "  '1',\n",
       "  'there',\n",
       "  'may',\n",
       "  'not',\n",
       "  'be',\n",
       "  'enough',\n",
       "  'characteristic',\n",
       "  'vectors',\n",
       "  'for',\n",
       "  't',\n",
       "  'to',\n",
       "  'span',\n",
       "  'the',\n",
       "  'space',\n",
       "  'v'],\n",
       " ['this', 'is', 'clearly', 'a', 'deficiency', 'in', 't']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Katz Back-off Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_dummy_words(list_of_s):\n",
    "    return [\"START\"] * 2 + list_of_s + [\"STOP\"]\n",
    "assert add_dummy_words([\"i\", \"eat\", \"apple\"]) == [\"START\", \"START\", \"i\", \"eat\", \"apple\", \"STOP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply adding dummy words\n",
    "dummy_ed = [add_dummy_words(li) for li in clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### class KatzBackoff():\n",
    "    def __init__(self, discount):\n",
    "        self.discount = discount\n",
    "\n",
    "    def build_ngrams(self, ngram, corpus):\n",
    "        ngrams = {}\n",
    "        if ngram == 0:\n",
    "            ngrams = {\n",
    "                (): {\n",
    "                    \"START\": len(corpus)\n",
    "                }\n",
    "            }\n",
    "        for i in range(len(corpus)):\n",
    "            raw = corpus[i]\n",
    "            core = raw[2:]\n",
    "            for cursor in range(2, len(raw)):\n",
    "                w0 = raw[cursor-2]\n",
    "                w1 = raw[cursor-1]\n",
    "                w2 = raw[cursor]\n",
    "                if ngram == 2:\n",
    "                    key = (w0,w1)\n",
    "                elif ngram == 1:\n",
    "                    key = (w1)\n",
    "                elif ngram == 0:\n",
    "                    key = ()\n",
    "                if key not in ngrams.keys():\n",
    "                    ngrams[key] = {}\n",
    "                    ngrams[key][w2] = 1\n",
    "                else:\n",
    "                    if w2 not in ngrams[key].keys():\n",
    "                        ngrams[key][w2] = 1\n",
    "                    else:\n",
    "                        ngrams[key][w2] += 1\n",
    "        return ngrams\n",
    "    1\n",
    "    def fit(self, corpus):\n",
    "        self.unigrams = self.build_ngrams(0, corpus)\n",
    "        self.bigrams = self.build_ngrams(1, corpus)\n",
    "        self.trigrams = self.build_ngrams(2, corpus)\n",
    "    \n",
    "    def calc_q(self, w2, w0, w1, level):\n",
    "        def get_count_fraction(key, ngrams, main_word):\n",
    "            count_combo = ngrams[key][main_word]\n",
    "            count_all = sum(ngrams[key].values())\n",
    "            return (count_combo - self.discount) / count_all\n",
    "\n",
    "        def get_alpha(key, ngrams, recorded_words):\n",
    "            summation = 0\n",
    "            for w2 in recorded_words:\n",
    "                summation += get_count_fraction(key, ngrams, w2)\n",
    "            return 1 - summation\n",
    "\n",
    "        if level == 0:\n",
    "            ngrams = self.unigrams\n",
    "            key = ()\n",
    "        elif level == 1:\n",
    "            ngrams = self.bigrams\n",
    "            key = (w1)\n",
    "        elif level == 2:\n",
    "            ngrams = self.trigrams\n",
    "            key = (w0, w1)\n",
    "\n",
    "        if key in ngrams.keys():\n",
    "            recorded_words = ngrams[key].keys()\n",
    "        else:\n",
    "            recorded_words = []\n",
    "\n",
    "        if w2 in recorded_words:\n",
    "            return get_count_fraction(key, ngrams, w2)\n",
    "        else:\n",
    "            if level != 0:\n",
    "                not_recorded_words = list(set(unigrams[()].keys()) - set(recorded_words))\n",
    "                return get_alpha(key, ngrams, recorded_words) * calc_q(w2, w0, w1, level-1) / sum([calc_q(w, w0, w1, level-1) for w in not_recorded_words])        \n",
    "            else:\n",
    "                return 1 - sum([get_count_fraction((), unigrams, x) for x in recorded_words])    \n",
    "            \n",
    "    def calc_sent_prob(self, input_sent):\n",
    "        res = 1.0\n",
    "        for i in range(2,len(input_sent)):\n",
    "            w0 = input_sent[i-2]\n",
    "            w1 = input_sent[i-1]\n",
    "            w2 = input_sent[i]\n",
    "            res *= self.calc_q(w2, w0, w1, 2)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kb = KatzBackoff(discount=0.01)\n",
    "t0 = time()\n",
    "kb.fit(dummy_ed)\n",
    "print(\"Fitting model took {:3f}\".format(time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = ['START', 'START', 'the', 'jury', 'further', 'said', 'in', 'terms']\n",
    "kb.calc_sent_prob(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foo = [1,2,3]\n",
    "bar = [10,20,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in foo:\n",
    "    if i < 10:\n",
    "        foo = bar\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "test_corpus = [\n",
    "    [\"START\", \"START\", \"i\", \"eat\", \"apple\", \"STOP\"],\n",
    "    [\"START\", \"START\", \"i\", \"eat\", \"meat\", \"STOP\"],\n",
    "    [\"START\", \"START\", \"vietnam\", \"has\", \"no\", \"enemy\", \"STOP\"],\n",
    "]\n",
    "kb = KatzBackoff(discount=0.01)\n",
    "kb.fit(test_corpus)\n",
    "test_sent = [\"START\", \"START\", \"i\", \"want\", \"to\", \"stay\", \"STOP\"]\n",
    "kb.calc_sent_prob(test_sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
